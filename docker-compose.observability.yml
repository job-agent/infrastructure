# Observability Stack
# This file contains monitoring and observability services.
# Requires core infrastructure (docker-compose.yml) to be running first.
#
# Usage:
#   docker compose -f docker-compose.observability.yml up -d
#
# Or use the convenience script:
#   ./scripts/start-all.sh

services:
  minio:
    image: minio/minio:RELEASE.2024-12-18T13-15-44Z
    container_name: minio
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    networks:
      - job-agent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  minio-init:
    # Using latest mc client - commands are stable across versions
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 $${MINIO_ROOT_USER:-minioadmin} $${MINIO_ROOT_PASSWORD:-minioadmin};
      mc mb myminio/tempo-traces --ignore-existing;
      mc mb myminio/loki-logs --ignore-existing;
      echo 'Buckets created successfully';
      exit 0;
      "
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    networks:
      - job-agent-network

  tempo:
    image: grafana/tempo:2.9.0
    container_name: tempo
    # Note: Running as root is required for write access to the tempo_data volume
    user: "0:0"
    ports:
      - "${TEMPO_PORT:-3200}:3200"
    volumes:
      - ./tempo-config.yaml:/etc/tempo.yaml:ro
      - tempo_data:/tmp/tempo
    command: -config.file=/etc/tempo.yaml
    networks:
      - job-agent-network
    depends_on:
      minio-init:
        condition: service_completed_successfully
    restart: unless-stopped

  loki:
    image: grafana/loki:3.3.2
    container_name: loki
    # Note: Running as root is required for write access to the loki_data volume
    user: "0:0"
    volumes:
      - ./loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - job-agent-network
    depends_on:
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.142.0
    container_name: otel-collector
    command: ["--config=/etc/otelcol-contrib/config.yaml"]
    ports:
      - "4317:4317"
    volumes:
      - ./otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      tempo:
        condition: service_started
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:13133/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - job-agent-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:12.3.1
    container_name: grafana
    ports:
      - "${GRAFANA_PORT:-3002}:3000"
    # SECURITY NOTE: Anonymous admin access is enabled for local development convenience.
    # For production deployments, disable anonymous access and configure proper authentication:
    #   GF_AUTH_ANONYMOUS_ENABLED=false
    #   GF_AUTH_DISABLE_LOGIN_FORM=false
    #   GF_SECURITY_ADMIN_PASSWORD=<strong_password>
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_DISABLE_LOGIN_FORM=true
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - job-agent-network
    depends_on:
      tempo:
        condition: service_started
      prometheus:
        condition: service_started
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - job-agent-network
    depends_on:
      cadvisor:
        condition: service_started
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:v0.15.0
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
    networks:
      - job-agent-network
    # Note: No depends_on for postgres since it's in a separate compose file.
    # The exporter will retry connecting until postgres is available.
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:9187/metrics || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.55.1
    container_name: cadvisor
    # SECURITY NOTE: Privileged mode is required for cAdvisor to access host container metrics.
    # This grants full host access - acceptable for local development but review for production.
    privileged: true
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - job-agent-network
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:8080/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  minio_data:
    driver: local
  tempo_data:
    driver: local
  loki_data:
    driver: local
  grafana_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  job-agent-network:
    external: true
    name: job-agent-network
